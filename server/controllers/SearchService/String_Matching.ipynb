{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "String_Matching.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_BTgUI--EiY",
        "outputId": "86e34c9d-812a-4a56-9e4a-34ed66565b9a"
      },
      "source": [
        "import string\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from polyfuzz import PolyFuzz\n",
        "import Levenshtein\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "stopwords=stopwords.words(\"english\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p9NYgFYQBgE2",
        "outputId": "954e56c0-1322-48ad-8c0f-49b75e977751"
      },
      "source": [
        "!pip install python-Levenshtein\n",
        "!pip install polyfuzz[all]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (54.2.0)\n",
            "Collecting polyfuzz[all]\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/00/632ac43b4c51e78dec784995db49861f7d6ac7b8ff00bb40127bd3e48854/polyfuzz-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.7/dist-packages (from polyfuzz[all]) (4.41.1)\n",
            "Collecting rapidfuzz>=0.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/b1/af677055e9d6a38c884c2ed809a820de68ec2627ad2fcb4b3b9706f97131/rapidfuzz-1.4.1-cp37-cp37m-manylinux2010_x86_64.whl (749kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 12.6MB/s \n",
            "\u001b[?25hCollecting numpy<=1.19.4,>=1.18.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/bb/87d668b353848b93baab0a64cddf6408c40717f099539668c3d26fe39f7e/numpy-1.19.4-cp37-cp37m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 286kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (from polyfuzz[all]) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from polyfuzz[all]) (1.1.5)\n",
            "Requirement already satisfied: joblib>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from polyfuzz[all]) (1.0.1)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from polyfuzz[all]) (0.11.1)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from polyfuzz[all]) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from polyfuzz[all]) (3.2.2)\n",
            "Collecting sparse-dot-topn>=0.2.9; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/d5/2a3a52acd89344f0c45cae320bd41ee49573caec656834b98c5ea48669b7/sparse_dot_topn-0.2.9.tar.gz (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 53.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.2.0; extra == \"all\" in /usr/local/lib/python3.7/dist-packages (from polyfuzz[all]) (1.8.1+cu101)\n",
            "Collecting flair>=0.7; extra == \"all\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/3a/1b46a0220d6176b22bcb9336619d1731301bc2c75fa926a9ef953e6e4d58/flair-0.8.0.post1-py3-none-any.whl (284kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 47.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->polyfuzz[all]) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->polyfuzz[all]) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->polyfuzz[all]) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->polyfuzz[all]) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->polyfuzz[all]) (1.3.1)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from sparse-dot-topn>=0.2.9; extra == \"all\"->polyfuzz[all]) (54.2.0)\n",
            "Requirement already satisfied: cython>=0.29.15 in /usr/local/lib/python3.7/dist-packages (from sparse-dot-topn>=0.2.9; extra == \"all\"->polyfuzz[all]) (0.29.22)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0; extra == \"all\"->polyfuzz[all]) (3.7.4.3)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/50/ba5ec9ff8b56e09c0aa8e13d2cc6e24b31bdd23e2bab8f510929bcc4ac48/ftfy-6.0.tar.gz (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair>=0.7; extra == \"all\"->polyfuzz[all]) (4.2.6)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/02/be/4dd30d56a0a19619deb9bf41ba8202709fa83b1b301b876572cd6dc38117/konoha-4.6.4-py3-none-any.whl\n",
            "Collecting transformers>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 37.1MB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair>=0.7; extra == \"all\"->polyfuzz[all]) (2019.12.20)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/73/994edfcba74443146c84b91921fcc269374354118d4f452fb0c54c1cbb12/Deprecated-1.2.12-py2.py3-none-any.whl\n",
            "Collecting sentencepiece==0.1.95\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 39.5MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 43.8MB/s \n",
            "\u001b[?25hCollecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair>=0.7; extra == \"all\"->polyfuzz[all]) (0.8.9)\n",
            "Collecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair>=0.7; extra == \"all\"->polyfuzz[all]) (3.6.0)\n",
            "Collecting gdown==3.12.2\n",
            "  Downloading https://files.pythonhosted.org/packages/50/21/92c3cfe56f5c0647145c4b0083d0733dd4890a057eb100a8eeddf949ffe9/gdown-3.12.2.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair>=0.7; extra == \"all\"->polyfuzz[all]) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.3->polyfuzz[all]) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair>=0.7; extra == \"all\"->polyfuzz[all]) (0.2.5)\n",
            "Collecting requests<3.0.0,>=2.25.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair>=0.7; extra == \"all\"->polyfuzz[all]) (3.8.1)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 32.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair>=0.7; extra == \"all\"->polyfuzz[all]) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair>=0.7; extra == \"all\"->polyfuzz[all]) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair>=0.7; extra == \"all\"->polyfuzz[all]) (1.12.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair>=0.7; extra == \"all\"->polyfuzz[all]) (4.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair>=0.7; extra == \"all\"->polyfuzz[all]) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair>=0.7; extra == \"all\"->polyfuzz[all]) (3.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair>=0.7; extra == \"all\"->polyfuzz[all]) (2.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.25.1->konoha<5.0.0,>=4.0.0->flair>=0.7; extra == \"all\"->polyfuzz[all]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.25.1->konoha<5.0.0,>=4.0.0->flair>=0.7; extra == \"all\"->polyfuzz[all]) (2020.12.5)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.25.1->konoha<5.0.0,>=4.0.0->flair>=0.7; extra == \"all\"->polyfuzz[all]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.25.1->konoha<5.0.0,>=4.0.0->flair>=0.7; extra == \"all\"->polyfuzz[all]) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair>=0.7; extra == \"all\"->polyfuzz[all]) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair>=0.7; extra == \"all\"->polyfuzz[all]) (7.1.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair>=0.7; extra == \"all\"->polyfuzz[all]) (4.4.2)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-cp37-none-any.whl size=9693 sha256=23255433f24146240194f15aa332b31218d3ce640a6106befa3b321ed9b42b77\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/d0/d7/d9983facc6f2775411803e0e2d30ebf98efbf2fc6e57701e09\n",
            "Successfully built gdown\n",
            "Building wheels for collected packages: sparse-dot-topn, ftfy, segtok, sqlitedict, langdetect, mpld3, overrides, sacremoses\n",
            "  Building wheel for sparse-dot-topn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sparse-dot-topn: filename=sparse_dot_topn-0.2.9-cp37-cp37m-linux_x86_64.whl size=324867 sha256=2474b46836b4de4518ec59e86a0f099a26049c34cd41537a03bc023a8da27bc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/e7/c7/e64559d518bcc12ed7e40a605ae304259b957ae8181c8d1e82\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0-cp37-none-any.whl size=41622 sha256=2d7bdcb35c6114d5f715db3fbc60770f4c8e49febcb038b5faafa4171d1cf238\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/8b/08/7d1c17849e10371206a262304973b5a9f45e8b9d0a2179f465\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp37-none-any.whl size=25019 sha256=71a1b0f4097c04761b1c995fdd0956669046610abeb9c01d852f4d40d1f2aeb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp37-none-any.whl size=14376 sha256=82372b3542782e3fec71ac33230705dae48eb649b0be6f6e4862a00b9a2f7403\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp37-none-any.whl size=993193 sha256=eb0bc5c4f0ebb4efadb7eca0ff5b1eaf09c30e70531e1dd43a661f0da2bc1979\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp37-none-any.whl size=116679 sha256=694751481ac11d98f79b4e536b16b3b559eea40f9be07fccbe97dd150aa75e4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=8b6bf4d0d0f31c475db7be6be7052554325bd64bf3967bdf57364be997b66971\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=5c3d4ad833a3bb37c120f8efd064b2a6955c1d7761505f204ae7f551210e3800\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sparse-dot-topn ftfy segtok sqlitedict langdetect mpld3 overrides sacremoses\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: flair 0.8.0.post1 has requirement torch<=1.7.1,>=1.5.0, but you'll have torch 1.8.1+cu101 which is incompatible.\u001b[0m\n",
            "Installing collected packages: rapidfuzz, numpy, sparse-dot-topn, ftfy, requests, overrides, konoha, sacremoses, tokenizers, transformers, segtok, deprecated, sentencepiece, huggingface-hub, sqlitedict, langdetect, mpld3, janome, gdown, bpemb, flair, polyfuzz\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "Successfully installed bpemb-0.3.2 deprecated-1.2.12 flair-0.8.0.post1 ftfy-6.0 gdown-3.12.2 huggingface-hub-0.0.8 janome-0.4.1 konoha-4.6.4 langdetect-1.0.8 mpld3-0.3 numpy-1.19.4 overrides-3.1.0 polyfuzz-0.2.2 rapidfuzz-1.4.1 requests-2.25.1 sacremoses-0.0.44 segtok-1.5.10 sentencepiece-0.1.95 sparse-dot-topn-0.2.9 sqlitedict-1.7.0 tokenizers-0.10.2 transformers-4.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHAw5mc9_krQ"
      },
      "source": [
        "sentences=[\n",
        "           \"This is a foobar sentence\",\n",
        "           \"This sentence is not similar to a foobar sentence\",\n",
        "           \"This is another string, but it is not quite similar to the previous ones\",\n",
        "           \"I am also just another string\",\n",
        "           \"Again not a foobar sentence\"\n",
        "]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uiODgu5_k4A"
      },
      "source": [
        "def clean_string(text):\n",
        "  text = ''.join([word for word in text if word not in string.punctuation])\n",
        "  text = text.lower()\n",
        "  text = ' '.join([word for word in text.split() if word not in stopwords])\n",
        "  return text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6sqw3hWAGUA",
        "outputId": "87d9b406-4427-4918-faa7-2acdd6cb5501"
      },
      "source": [
        "cleaned = list(map(clean_string,sentences))\n",
        "print(cleaned)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['foobar sentence', 'sentence similar foobar sentence', 'another string quite similar previous ones', 'also another string']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO9p9UuIA3St",
        "outputId": "22a9b08f-0519-47aa-d452-471f70f6494d"
      },
      "source": [
        "vectorizer = CountVectorizer().fit_transform(cleaned)\n",
        "vectors = vectorizer.toarray()\n",
        "print(vectors)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 1 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 2 1 0]\n",
            " [0 1 0 1 1 1 0 1 1]\n",
            " [1 1 0 0 0 0 0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvDta6SrBM9v",
        "outputId": "82f4c3be-5637-478e-c3e3-1035a8224466"
      },
      "source": [
        "csim = cosine_similarity(vectors)\n",
        "print(csim)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.8660254  0.         0.        ]\n",
            " [0.8660254  1.         0.16666667 0.        ]\n",
            " [0.         0.16666667 1.         0.47140452]\n",
            " [0.         0.         0.47140452 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO_EYjS4BcOy",
        "outputId": "1e10df85-b9ed-4b15-fc7d-997cb6333b68"
      },
      "source": [
        "Levenshtein.distance(sentences[2],sentences[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "ON8v0dth1elK",
        "outputId": "23f6479e-8a54-4b76-bdb9-9ece5fbe9d95"
      },
      "source": [
        "from_list = [\"this is an apple\", \"these are apples\"]\n",
        "to_list = [\"these are many apples\"]\n",
        "\n",
        "model = PolyFuzz(\"EditDistance\")\n",
        "# model = PolyFuzz(\"TF-IDF\")\n",
        "# model = PolyFuzz(\"Embeddings\")\n",
        "\n",
        "model.match(from_list, to_list)\n",
        "\n",
        "model.get_matches()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 16:55:05,322 https://flair.informatik.hu-berlin.de/resources/embeddings/token/en-fasttext-news-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpgjasun0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1200000128/1200000128 [01:06<00:00, 18018851.18B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 16:56:12,478 copying /tmp/tmpgjasun0s to cache at /root/.flair/embeddings/en-fasttext-news-300d-1M.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 16:56:23,979 removing temp file /tmp/tmpgjasun0s\n",
            "2021-04-11 16:56:24,619 https://flair.informatik.hu-berlin.de/resources/embeddings/token/en-fasttext-news-300d-1M not found in cache, downloading to /tmp/tmp4hjvzhsd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54600983/54600983 [00:03<00:00, 14079988.28B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-11 16:56:29,040 copying /tmp/tmp4hjvzhsd to cache at /root/.flair/embeddings/en-fasttext-news-300d-1M\n",
            "2021-04-11 16:56:29,110 removing temp file /tmp/tmp4hjvzhsd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>From</th>\n",
              "      <th>To</th>\n",
              "      <th>Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this is an apple</td>\n",
              "      <td>these are many apples</td>\n",
              "      <td>0.742809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>these are apples</td>\n",
              "      <td>these are many apples</td>\n",
              "      <td>0.976916</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               From                     To  Similarity\n",
              "0  this is an apple  these are many apples    0.742809\n",
              "1  these are apples  these are many apples    0.976916"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BY8Wt4LW3aYX",
        "outputId": "98297c05-82d9-4efc-c0ab-2c3d12bf69e5"
      },
      "source": [
        "tfidf = TfidfVectorizer().fit_transform(sentences)\n",
        "pairwise_similarity = tfidf * tfidf.T\n",
        "arr=pairwise_similarity.toarray()\n",
        "np.fill_diagonal(arr, np.nan)\n",
        "result_idx = np.nanargmax(arr[tfidf.shape[0]-1])\n",
        "print(sentences[result_idx])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This sentence is not similar to a foobar sentence\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}